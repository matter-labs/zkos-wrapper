use super::*;

use serde::de;
use zkos_verifier::prover::nd_source_std::ThreadLocalBasedSource;

// wrapping NonDeterminismSource functions:
pub(crate) fn read_word<
    F: SmallField,
    CS: ConstraintSystem<F>,
    I: NonDeterminismSource,
>(cs: &mut CS) -> UInt32<F> {
    UInt32::allocate_checked(cs, I::read_word())
}

pub(crate) fn read_mersenne_element<
    F: SmallField,
    CS: ConstraintSystem<F>,
    I: NonDeterminismSource,
>(cs: &mut CS) -> MersenneField<F> {
    let modulus = Mersenne31Field::CHARACTERISTICS as u32;
    let witness = Mersenne31Field::from_nonreduced_u32(I::read_reduced_field_element(modulus));
    MersenneField::allocate_checked(cs, witness, false)
}

pub trait CircuitLeafInclusionVerifier<F: SmallField> {
    fn new<CS: ConstraintSystem<F>>(cs: &mut CS) -> Self;

    fn verify_leaf_inclusion<
        CS: ConstraintSystem<F>,
        I: NonDeterminismSource,
        const CAP_SIZE: usize,
        const NUM_COSETS: usize,
    >(
        &mut self,
        cs: &mut CS,
        coset_index: &[Boolean<F>],
        leaf_index: &[Boolean<F>],
        depth: usize,
        leaf_encoding: &[MersenneField<F>],
        merkle_cap: &[WrappedMerkleTreeCap<F, CAP_SIZE>; NUM_COSETS],
    ) -> Boolean<F>;
}

use zkos_verifier::blake2s_u32::{BLAKE2S_BLOCK_SIZE_U32_WORDS, BLAKE2S_DIGEST_SIZE_U32_WORDS};

#[derive(Debug)]
pub struct CircuitBlake2sForEverythingVerifier<F: SmallField> {
    hasher: Blake2sStateGate<F>,
}

impl<F: SmallField> CircuitLeafInclusionVerifier<F> for CircuitBlake2sForEverythingVerifier<F> {
    fn new<CS: ConstraintSystem<F>>(cs: &mut CS) -> Self {
        Self {
            hasher: Blake2sStateGate::new(cs),
        }
    }

    fn verify_leaf_inclusion<
        CS: ConstraintSystem<F>,
        I: NonDeterminismSource,
        const CAP_SIZE: usize,
        const NUM_COSETS: usize,
    >(
        &mut self,
        cs: &mut CS,
        coset_index: &[Boolean<F>],
        leaf_index: &[Boolean<F>],
        depth: usize,
        leaf_encoding: &[MersenneField<F>],
        merkle_cap: &[WrappedMerkleTreeCap<F, CAP_SIZE>; NUM_COSETS],
    ) -> Boolean<F> {
        // our strategy is:
        // - since leaf is used for other purposes, we have to copy it into the buffer, no options here
        // - but when we output the leaf hash, we will put it into the input buffer of our first of `merkle_path_hashers`,
        // and then alternate between them
        self.hasher.reset();

        let input_len_words = leaf_encoding.len();
        let mut num_full_rounds = input_len_words / BLAKE2S_BLOCK_SIZE_U32_WORDS;
        let mut last_round_len = input_len_words % BLAKE2S_BLOCK_SIZE_U32_WORDS;
        if last_round_len == 0 {
            if num_full_rounds > 1 {
                num_full_rounds -= 1;
            }
            last_round_len = BLAKE2S_BLOCK_SIZE_U32_WORDS;
        }

        // full rounds, unrolled
        unsafe {
            let mut src_ptr = leaf_encoding.as_ptr();
            for _ in 0..num_full_rounds {
                let input_slice = core::slice::from_raw_parts(src_ptr, BLAKE2S_BLOCK_SIZE_U32_WORDS);
                self.hasher.input_buffer
                    .iter_mut()
                    .zip(input_slice)
                    .for_each(|(dst, src)| {
                        *dst = Word { inner: src.into_uint32().to_le_bytes(cs) };
                    });

                self.hasher.run_round_function::<CS, USE_REDUCED_BLAKE2_ROUNDS>(
                    cs,
                    BLAKE2S_BLOCK_SIZE_U32_WORDS,
                    false,
                );
                src_ptr = src_ptr.add(BLAKE2S_BLOCK_SIZE_U32_WORDS);
            }

            // last round unrolled padding
            {
                let input_slice = core::slice::from_raw_parts(src_ptr, last_round_len);
                self.hasher.input_buffer[..last_round_len]
                    .iter_mut()
                    .zip(input_slice)
                    .for_each(|(dst, src)| {
                        *dst = Word { inner: src.into_uint32().to_le_bytes(cs) };
                    });
                self.hasher.input_buffer[last_round_len..].iter_mut().for_each(|el| {
                    *el = Word {
                        inner: [UInt8::zero(cs); 4],
                    };
                });
                self.hasher.run_round_function::<CS, USE_REDUCED_BLAKE2_ROUNDS>(
                    cs,
                    last_round_len,
                    true,
                );
            }
        }

        // now hash output is in state, and we will use it to verify a path below by asking for witness elements
        let absolute_tree_index_bits = leaf_index
            .iter()
            .chain(coset_index.iter())
            .cloned()
            .collect::<Vec<_>>();
        let (head, middle, tail) = unsafe {
            merkle_cap.align_to::<[UInt32<F>; DIGEST_SIZE_U32_WORDS]>()
        };
        assert!(head.is_empty() && tail.is_empty());
        let merkle_cap_flattened = middle;

        if depth == 0 {
            let cap = binary_parallel_select(cs, merkle_cap_flattened, &absolute_tree_index_bits);
            let output_hash = self.hasher.read_state_for_output();
            let equalities: [_; DIGEST_SIZE_U32_WORDS] = std::array::from_fn(|idx| 
                {
                    let a = cap[idx].into_num();
                    let b = UInt32::from_le_bytes(cs, output_hash[idx].inner).into_num();
                    Num::equals(cs, &a, &b)
                }
            );
            let equal = Boolean::multi_and(cs, &equalities);
            return equal;
        }

        // every step we:
        // - copy previous from the state into corresponding place of the input buffer
        // - place witness elements into the other part of input buffer
        // - run round function
        for i in 0..depth {
            let current_state = self.hasher.read_state_for_output();
            let witness_dst: [Word<F>; 8] = std::array::from_fn(|_idx| {
                    let word = read_word::<F, CS, I>(cs);
                    Word { inner: word.to_le_bytes(cs) }
                }
            );
            let input_is_right = leaf_index[i];
            self.hasher.input_buffer[..BLAKE2S_DIGEST_SIZE_U32_WORDS]
                .iter_mut()
                .zip(current_state.iter())
                .zip(witness_dst.iter())
                .for_each(|((dst, current), witness)| {
                    (*dst).inner = UInt8::parallel_select(cs, input_is_right, &witness.inner, &current.inner);
                });
            self.hasher.input_buffer[BLAKE2S_DIGEST_SIZE_U32_WORDS..]
                .iter_mut()
                .zip(current_state.iter())
                .zip(witness_dst.iter())
                .for_each(|((dst, current), witness)| {
                    (*dst).inner = UInt8::parallel_select(cs, input_is_right, &current.inner, &witness.inner);
                });

            self.hasher.reset();
            self.hasher.run_round_function::<CS, USE_REDUCED_BLAKE2_ROUNDS>(
                cs,
                BLAKE2S_BLOCK_SIZE_U32_WORDS,
                true,
            );
        }

        // here we manually compare, otherwise it's compiled as memcmp that does by byte(!) comparison
        let cap = binary_parallel_select(cs, merkle_cap_flattened, &absolute_tree_index_bits[depth..]);
        let output_hash = self.hasher.read_state_for_output();
        let equalities: [_; DIGEST_SIZE_U32_WORDS] = std::array::from_fn(|idx| 
            {
                let a = cap[idx].into_num();
                let b = UInt32::from_le_bytes(cs, output_hash[idx].inner).into_num();
                Num::equals(cs, &a, &b)

                // let ans = Num::equals(cs, &a, &b);
                // let ans_val = ans.witness_hook(cs)().unwrap();
                // println!("ans_val: {:?}", ans_val);
                // ans
            }
        );
        let equal = Boolean::multi_and(cs, &equalities);

        equal
    }
}
